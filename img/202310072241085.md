

# Flume

## 1. 概述:

```
flume:一个高可用的,高可靠,分布式的海量-日志-采集,聚合和传输的系统.
更多的会上传到hdfs,动态采集方式.
---
它有三个组成
source: 监控数据
channel: 作为source和sink之间的缓冲区,保证了source和sink在不同速率也可以正常运行.它自带两种转换方式1. Memory Channel(内存队列)和File Channel(磁盘)
但是更好的方式存储到kafka中.
sink: 将channel的数据批量的写入到不同的存储位置.
event: 事件
```

![image-20230805101134365](D:/typora/image/.assets/image-20230805101134365.png)

## 2. 创建过程

```
1.先进行解压安装
2.创建一个job文件夹,文件夹中创建一个关于数据在source,channel, sink中的配置文件,Xxx.conf
3.上述的Xxx.conf文件可以根据个人的需求从官网上进行对应书写.
https://flume.apache.org/releases/content/1.11.0/FlumeUserGuide.html
```

![image-20230805120032016](D:/typora/image/.assets/image-20230805120032016.png)

```
上述文件是flume在上传文件时断点续传的一个json文件,用于存储当上传的文件出现问题的时候,可以在出错的地方继续上传,而不是从头开始上传.
------其中一种方式-------------
inode: 系统中的文件的唯一标识(只有创建新的文件的时候才会改变)
pos: 文件字节数
file: 文件的绝对路径
默认的是: file和inode共同决定pos
------------
使用taildir的方式,可能会出现一些问题
-----
一个简单的例子: 当你要监控一个文件夹,文件夹中有a.txt,此时向a.txt中写入10个字节文件(flume监控到数据后,进行上传到hdfs上),此时再次添加5个字节文件(监控到,也会上传到hdfs),所以此时a.txt共有15个字节文件. --但是此时对a.txt进行更改文件名b.txt ,此时产生了新的文件,所以flume还会进行监控b.txt中的15个字节文件都会被上传.(但是我们已经将数据上传过,而上述taildir.json文件并没有起到作用), 原因taildir.json中的inode和file共同决定上传的文件.-->但是此时改变了file文件所以会重新将文件上传.
-----
```

![image-20230805122357143](D:/typora/image/.assets/image-20230805122357143.png)

```
应用方面:
列如: 当你监控日志文件的时候,当天的日志会存储在hive.log中,但是hive一直在运行当到达凌晨12:00的时候他就会更名为hive.log.2020.10.1日志的形式,然后重新创建一个hive.log
```

![image-20230805122515279](D:/typora/image/.assets/image-20230805122515279.png)

```
出现的问题: 此时产生了更名操作,flume监控会将更名后的数据再次上传.
---解决方式1: 如果将flume监控的日志写死为hive.log, 此时也会出现一些问题:就是当你监控hive.log在11:55出现了问题,但是此时没有发现,到了第二天重启监控的时候,hive.log会自动改名为hive.log.2020.10.3, 由于flume只能监控hive.log所以此时就会出现数据丢失.
```

解决方案: 

1. 让写后台的不要用会更名的方式保存日志.

2. 改源码将taildir的一个源码.如下将path.equals(path)删除

注意读和写都需要修改

![image-20230805124146217](https://raw.githubusercontent.com/ValidationExpression/typora_image/main/img/202310072201255.png)

![image-20230805124250492](D:/typora/image/.assets/image-20230805124250492.png)

## 3. flume企业开发案例

1. 复制和多路复用

![image-20230806094346886](D:/typora/image/.assets/image-20230806094346886.png)

![image-20230806094419112](D:/typora/image/.assets/image-20230806094419112.png)

```markdown
需求: 一个flume_1的agent采集数据,然后串联flume_2,flume_3,
flume_2的sink将数据上传到hdfs, flume_3的sink将数据上传到file row
------------------------------------------------------------------
# Name the components on this agent
a1.source= r1
a1.sink = k1 k2
a1.channels = c1 c2
# 将数据流复制给所有的channel (默认的会自动复制给其他channel所以可以不用写)
a1.source.r1.selector.type = replicating

# Describr/configure the source --(下方的source只需要根据官网的提示书写即可)
a1.sources.r1.type = exec 可以换成你所需要的类型(官网)
a1.sources.r1.command = tail -F /要采集日志的路径
a1.sources.r1.shell = /bin/bash -c 

# sink端avro发送数据(avro一般在两个flume串联的时候使用)
a1.sinks.k1.type = avro
a1.sinks.k1.hostname = hadoop102  //地址可以在不同的机器
a1.sinks.k1.port = 4545    //端口号这里的端口号应当为服务端的

a1.sinks.k2.type = avro
a1.sinks.k2.hostname = hadoop102  //地址
a1.sinks.k2.port = 4546    //端口号
# Describe the channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.channels.c2.type = memory
a1.channels.c2.capacity = 1000
a1.channels.c2.transactionCapacity = 100
# 绑定source and sink to channel
a1.sources.r1.channels = c1 c2  //有副本所以绑定两个channel
a1.sinks.k1.channel = c1
a1.sinks.k2.channel = c2

# flume_2和flume_3只需要改变上述的source和sink即可
```

2. 负载均衡和故障转移

![image-20230806102306747](D:/typora/image/.assets/image-20230806102306747.png)

故障转移: flume_2的优先级高于flume_3当flume_2挂掉时, flume_3才会启动.

![image-20230806102513405](D:/typora/image/.assets/image-20230806102513405.png)

```markdown
# Name the components on this agent
a1.source= r1
a1.sink = k1 k2
a1.channels = c1
a1.sinkgroups = g1  //声明组

# Describr/configure the source --(下方的source只需要根据官网的提示书写即可)
a1.sources.r1.type = netcat 可以换成你所需要的类型(官网)
a1.sources.r1.bind = localhost
a1.sources.r1.post = 44444

a1.sinkgroups.g1.processor.type = failover  // 配置组的类型->故障转移
# a1.sinkgroups.g1.processor.type = load_balance 负载均衡 下面的优先级不再需要
# 负载均衡可能会出现一个问题: 原本接收数据是轮询的形式,flume_2一条,flume_3一条交替进行
# 但是他出现了不轮询的情况,原因它们有一个时间,就是flume_2接收的时候有数据发送过来,但是当轮到flume_3接收的时候,此时没有数据了,所以他没有接收到,再次到flume_2接收的时候又有数据了,他会再次接收到,以此解释有时候不是
a1.sinkgroups.g1.processor.priority.k1 = 5  //设置优先级
a1.sinkgroups.g1.processor.priority.k2 =10  
a1.sinkgroups.g1.processor.maxpenalty = 10000

# sink端avro发送数据(avro一般在两个flume串联的时候使用)
a1.sinks.k1.type = avro
a1.sinks.k1.hostname = hadoop102  //地址可以在不同的机器
a1.sinks.k1.port = 4545    //端口号这里的端口号应当为服务端的

a1.sinks.k2.type = avro
a1.sinks.k2.hostname = hadoop102  //地址
a1.sinks.k2.port = 4546    //端口号
# Describe the channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100
# 绑定source and sink to channel
a1.sources.r1.channels = c1 
a1.sinkgroups.g1.sinks = k1 k2  //绑定k1 k2
a1.sinks.k1.channel = c1
a1.sinks.k2.channel = c1

```

3. 聚合

![image-20230806155824749](D:/typora/image/.assets/image-20230806155824749.png)

  配置方式

![image-20230807101108861](D:/typora/image/.assets/image-20230807101108861.png)

```
都要先启动服务端
------------------
conf文件大部分同上
1. flume_1: source是 一个日志文件(根据不同的方式获取)
            sink: type: avro, hostname: hadoop104 (两个flume之间传输使用avro)
2. flume_2: source: netcat(接收端口的数据)
            sink: 同上
3. flume_3: source: avro(接收来自flume_1和flume_2的数据)
            sink: 传输的位置(hdfs,logger)
```

## 4. 自定义Intercetor(拦截器)

需求分析

![image-20230807102757529](D:/typora/image/.assets/image-20230807102757529.png)

1. 配置流程

```markdown
1. 配置Xxx.conf文件的selector
--------------------------
a1.sources = r1
a1.channels = c1 c2 c3 c4  //根据自己的需要进行改变
# 进行绑定
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = com.atguigu.ad.flume.interceptor.TypeInterceptor$Builder  //全类名
# 类型
a1.soueces.r1.selector.type = multiplexing
# event 头信息(类似于switch(a)中的a
a1.sources.r1.selector.header = state   //然后可以根据代码的key进行相应的匹配
# event的头信息的格式为map(k-v)的形式. 所以可以根据不同的k进行区分,放入到相应的channel中
a1.sources.r1.selector.maping.CZ = c1
# US就放入到c2, c3 中
a1.sources.r1.selector.maping.US = c2 c3
# 其他类型放入到c4
al.sources.r1.selector.default=c4

------------
在配置sink
...
```

2. 编写maven项目

```
   继承有一个Interceptor接口(flume包下的),然后会重写相应的方法,pom.xml文件要加上相应的依赖.
```

![image-20230807104228511](D:/typora/image/.assets/image-20230807104228511.png)

实现流程如java文件

```java
D:\VMwareCentos\adsProject\mavenProject\ad_flume_interceptor\src\main\java\com\atguigu\ad\flume\interceptor\TypeInterceptor.java
---------------------
package com.atguigu.ad.flume.interceptor;

public class TypeInterceptor implements Interceptor {
    //创建以一个全局的集合,用于存储拦截器处理后的数据
    private List<Event> list;
    @Override
    public void initialize() {
        //对集合初始化
        list = new ArrayList<>();
    }
    //单个事件处理方法
    @Override
    public Event intercept(Event event) {

        /**
         * header是一个map，body是一个字节数组，body才是我们实际使用中真正传输的数据，
         * header传输的数据，我们是不会是sink出去的,
         * body的数据是经过序列化的一个数组
         */
        //获取头信息,它是map类型(K-V)
        Map<String, String> headers = event.getHeaders();
        //获取数据体
        //byte[] body = event.getBody(); 由于他返回的是byte[]数组,所以要进行数据转换
        String s = new String(event.getBody());
        //可以根据body中是否含有某个数据,将所需的数据写入到header头中,进行判断
        if (s.contains("aaa")){
            //这里的put("key","value")注意要和在conf中配置的相同
            /**
             * # event 头信息(类似于switch(a)中的a
             * a1.sources.r1.selector.header = state
             * # event的头信息的格式为map(k-v)的形式. 所以可以根据不同的k进行区分,放入到相应的channel中
             * a1.sources.r1.selector.maping.CZ = c1
             * # US就放入到c2, c3 中
             * a1.sources.r1.selector.maping.US = c2 c3
             * # 其他类型放入到c4
             * al.sources.r1.selector.default=c4
             */
            headers.put("state","CZ");
        }else {
            headers.put("state","US");
        }
        return event;
    }
    //多个事件处理方法
    @Override
    public List<Event> intercept(List<Event> events) {
        //对原集合的数据进行清空
        list.clear();
        //遍历集合
        for (Event event : events) {
            //调用上述处理一条数据的方法
            list.add(intercept(event));
        }
        return list;
    }
    @Override
    public void close() {}
    /**
     * 创建一个builder对象,实例化TypeInterceptorl拦截器对象
     */
    public static class Builder implements Interceptor.Builder{
        @Override
        public Interceptor build() {
            return new TypeInterceptor();
        }
        @Override
        public void configure(Context context) {}
    }
}
```

3. 将上述的文件进行打包操作,上传到  flume/lib文件夹下

## 5.自定义source

```
可以自定义监控的数据类型,例如mysql等其他类型,官方文档没有的
```

![image-20230807154504267](D:/typora/image/.assets/image-20230807154504267.png)

![image-20230807154605663](D:/typora/image/.assets/image-20230807154605663.png)

1. 流程类似于过滤器

```
不同的地方: source
a1.sources.r1.type = (自定义)的全类名
```

## 6. 自定义sink

[flume自定义官网](https://flume.apache.org/releases/content/1.11.0/FlumeDeveloperGuide.html)

## 7.flume事务

![image-20230807205340753](D:/typora/image/.assets/image-20230807205340753.png)

```
1. put事务: 如果回滚会清除掉所有的putList数据.(put根据不同的source的不同可能会出现数据丢失的情况,例如netcat只会接收最新的数据,而tailor不会丢失数据)
2. take事务: 如果回滚将takeList会预留回滚的数据空间,以保证回滚的数据可以存储.
```

## 8. flume面试题

1. flume数据监控

```
使用的是第三方框架Ganglia实时监控flume
```

2. Flume的Source, Sink, Channel的作用? Source的类型?

![image-20230807214832995](D:/typora/image/.assets/image-20230807214832995.png)

```
主要会使用tailor source, 它可以实时监控数据,还可以断点续传.
```

3. Flume的Channel Selectors

![image-20230807215211654](D:/typora/image/.assets/image-20230807215211654.png)

4. Flume的事务

![image-20230807215441379](D:/typora/image/.assets/image-20230807215441379.png)

5. Flume采集数据会丢失数据吗?

![image-20230807215518645](D:/typora/image/.assets/image-20230807215518645.png)
